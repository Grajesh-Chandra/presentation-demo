# Kong Configuration Files

This directory contains Kong Gateway configuration files generated by the setup scripts.

## Configuration Evolution

Each configuration file represents a step in the Kong setup process:

| File | Generated By | Status | Description |
|------|-------------|---------|-------------|
| `01-kong-basic.yaml` | `12-configure-kong-basic.sh` | ✅ Working | Basic services and routes only |
| `02-kong-with-auth.yaml` | `13-add-authentication.sh` | ✅ Working | Key-auth and rate-limiting (local policy) |
| `03-kong-with-ai-proxy.yaml` | `14-add-ai-proxy.sh` | ✅ Working | AI Proxy for Gemini and Ollama |
| `04-kong-complete.yaml` | `15-add-ai-security.sh` | ✅ Working | Complete with security features |
| `05-kong-with-semantic-cache.yaml` | `17-add-semantic-cache.sh` | ❌ Enterprise | Semantic caching (not available) |
| `06-kong-with-ollama-fixed.yaml` | `07-fix-ollama-config.sh` | ✅ Deployed | Fixed Ollama (llama2 provider) |
| `07-kong-with-redis-plugins.yaml` | `08-add-redis-plugins.sh` | ✅ Deployed | Redis-backed rate limiting |
| `08-kong-with-semantic-guard.yaml` | `10-add-semantic-prompt-guard.sh` | ❌ Enterprise | Vector-based security (not available) |

## Usage

These files are used with decK to sync configuration to Kong Konnect:

```bash
deck gateway sync \
  --konnect-control-plane-name="Kong-Demo" \
  --konnect-addr="https://in.api.konghq.com" \
  --konnect-token="YOUR_TOKEN" \
  plugins/01-kong-basic.yaml
```

## Configuration Progression

### 01-kong-basic.yaml
- Services: demo-api, ai-router
- Routes: Basic routing to backend services
- Plugins: None

### 02-kong-with-auth.yaml
- Everything from 01-kong-basic.yaml
- Consumers: demo-user, power-user
- Plugins: key-auth, rate-limiting (local policy)

### 03-kong-with-ai-proxy.yaml
- Everything from 02-kong-with-auth.yaml
- Services: ollama-mistral, gemini-flash
- Routes: AI-specific routes
- Plugins: ai-proxy (for Gemini and Ollama)

### 04-kong-complete.yaml
- Everything from 03-kong-with-ai-proxy.yaml
- Plugins: ai-prompt-guard, response-transformer, ai-request-transformer
- Complete production-ready configuration

### 06-kong-with-ollama-fixed.yaml
- Fixed Ollama configuration with llama2 provider
- Fixes: "expected one of: openai, azure, anthropic..." error
- Configuration: provider: llama2, llama2_format: "openai"

### 07-kong-with-redis-plugins.yaml
- Migrated all rate-limiting plugins from local to Redis
- Redis Cloud integration (SSL enabled)
- 6 rate-limiting plugins updated with Redis backend

### 08-kong-with-semantic-guard.yaml
- Added ai-semantic-prompt-guard plugin
- Vector-based prompt injection detection
- Gemini text-embedding-004 for embeddings
- Redis as vector database
- 8 malicious prompt patterns configured

## Important Notes

1. **Latest Production Config**: `07-kong-with-redis-plugins.yaml` (Redis-backed rate limiting)
2. **API Keys**: Defined in auth configs
   - demo-user: `demo-api-key-12345` (10 req/min)
   - power-user: `power-key-67890` (50 req/min)
3. **AI Services**: Require external setup (Ollama, Gemini API key)
4. **Region**: Configured for Kong Konnect India region
5. **Enterprise Features**: Configs 05 and 08 require Enterprise license
6. **Ollama Fix**: Config 06 fixes provider compatibility issue
