_format_version: "3.0"

services:
  # Demo API Service
  - name: demo-api-service
    url: http://host.docker.internal:3000
    routes:
      - name: demo-api-route
        paths:
          - /api/demo
        strip_path: true
        plugins:
          - name: key-auth
            config:
              key_names:
                - apikey
          # Redis-backed rate limiting (centralized across all Kong nodes)
          - name: rate-limiting
            config:
              minute: 10
              policy: redis
              redis:
                host: redis-11926.crce179.ap-south-1-1.ec2.redns.redis-cloud.com
                port: 11926
                username: default
                password: ezVdcJrF68Cq5hebnsv3AwUBIlC0ffu2
                database: 0
                ssl: true
                ssl_verify: false
                server_name: redis-11926.crce179.ap-south-1-1.ec2.redns.redis-cloud.com
          - name: correlation-id
            config:
              header_name: Kong-Request-ID
              generator: uuid
              echo_downstream: true
          - name: response-transformer
            config:
              add:
                headers:
                  - "X-Kong-Demo:true"
                  - "X-Service:demo-api"
                  - "X-Cache-Backend:redis"

  # AI Router Service (Custom Flask App)
  - name: ai-router-service
    url: http://host.docker.internal:8080
    routes:
      # Public health endpoint
      - name: ai-health-route
        paths:
          - ~/ai/health$
        strip_path: false
        plugins:
          - name: request-transformer
            config:
              replace:
                uri: /health
          - name: correlation-id
            config:
              header_name: Kong-Request-ID
              generator: uuid
              echo_downstream: true

      # Custom AI Router endpoints (with auth)
      - name: ai-custom-route
        paths:
          - /ai/custom
        strip_path: true
        plugins:
          - name: key-auth
            config:
              key_names:
                - apikey
          # Redis-backed rate limiting
          - name: rate-limiting
            config:
              minute: 20
              policy: redis
              redis:
                host: redis-11926.crce179.ap-south-1-1.ec2.redns.redis-cloud.com
                port: 11926
                username: default
                password: ezVdcJrF68Cq5hebnsv3AwUBIlC0ffu2
                database: 0
                ssl: true
                ssl_verify: false
                server_name: redis-11926.crce179.ap-south-1-1.ec2.redns.redis-cloud.com
          - name: correlation-id
            config:
              header_name: Kong-Request-ID
              generator: uuid
              echo_downstream: true
          - name: response-transformer
            config:
              add:
                headers:
                  - "X-Kong-Demo:true"
                  - "X-Service:ai-router-custom"
                  - "X-Cache-Backend:redis"

  # Kong Native AI - Ollama Service (using llama2 provider)
  - name: ai-ollama-service
    url: http://host.docker.internal:11434
    routes:
      - name: ai-ollama-chat-route
        paths:
          - /ai/kong/ollama/chat
        strip_path: true
        plugins:
          - name: key-auth
            config:
              key_names:
                - apikey
          # Redis-backed rate limiting (centralized)
          - name: rate-limiting
            config:
              minute: 20
              policy: redis
              redis:
                host: redis-11926.crce179.ap-south-1-1.ec2.redns.redis-cloud.com
                port: 11926
                username: default
                password: ezVdcJrF68Cq5hebnsv3AwUBIlC0ffu2
                database: 0
                ssl: true
                ssl_verify: false
                server_name: redis-11926.crce179.ap-south-1-1.ec2.redns.redis-cloud.com
          - name: ai-proxy
            config:
              route_type: "llm/v1/chat"
              auth:
                header_name: Authorization
                header_value: "Bearer dummy"
              logging:
                log_statistics: true
                log_payloads: true
              model:
                provider: "llama2"
                name: "mistral"
                options:
                  max_tokens: 512
                  temperature: 0.7
                  llama2_format: "openai"
                  upstream_url: "http://host.docker.internal:11434/v1/chat/completions"
          - name: ai-prompt-guard
            config:
              allow_patterns:
                - ".*"
              deny_patterns:
                - "ignore previous instructions"
                - "ignore all previous"
                - "act as DAN"
                - "do anything now"
                - "jailbreak"
                - "bypass"
                - "system prompt"
                - "forget your instructions"
          - name: correlation-id
            config:
              header_name: Kong-Request-ID
              generator: uuid
              echo_downstream: true
          - name: response-transformer
            config:
              add:
                headers:
                  - "X-Kong-Demo:true"
                  - "X-Service:ai-ollama"
                  - "X-AI-Provider:ollama"
                  - "X-Cache-Backend:redis"
          - name: request-size-limiting
            config:
              allowed_payload_size: 5

  # Kong Native AI - Gemini Service
  - name: ai-gemini-service
    url: https://generativelanguage.googleapis.com
    routes:
      - name: ai-gemini-chat-route
        paths:
          - /ai/kong/gemini/chat
        strip_path: true
        plugins:
          - name: key-auth
            config:
              key_names:
                - apikey
          # Redis-backed rate limiting (centralized)
          - name: rate-limiting
            config:
              minute: 20
              policy: redis
              redis:
                host: redis-11926.crce179.ap-south-1-1.ec2.redns.redis-cloud.com
                port: 11926
                username: default
                password: ezVdcJrF68Cq5hebnsv3AwUBIlC0ffu2
                database: 0
                ssl: true
                ssl_verify: false
                server_name: redis-11926.crce179.ap-south-1-1.ec2.redns.redis-cloud.com
          - name: ai-proxy
            config:
              route_type: "llm/v1/chat"
              auth:
                header_name: "x-goog-api-key"
                header_value: "AIzaSyAR5tOATz7L-NfG2jTHuvw0WNyYwqxTwoA"
              logging:
                log_statistics: true
                log_payloads: true
              model:
                provider: "gemini"
                name: "gemini-2.0-flash-exp"
                options:
                  max_tokens: 512
                  temperature: 0.7
          - name: ai-prompt-guard
            config:
              allow_patterns:
                - ".*"
              deny_patterns:
                - "ignore previous instructions"
                - "ignore all previous"
                - "act as DAN"
                - "do anything now"
                - "jailbreak"
                - "bypass"
                - "system prompt"
                - "forget your instructions"
          - name: correlation-id
            config:
              header_name: Kong-Request-ID
              generator: uuid
              echo_downstream: true
          - name: response-transformer
            config:
              add:
                headers:
                  - "X-Kong-Demo:true"
                  - "X-Service:ai-gemini"
                  - "X-AI-Provider:gemini"
                  - "X-Cache-Backend:redis"
          - name: request-size-limiting
            config:
              allowed_payload_size: 5

consumers:
  - username: demo-user
    keyauth_credentials:
      - key: demo-api-key-12345
    plugins:
      # Redis-backed rate limiting per consumer
      - name: rate-limiting
        config:
          minute: 10
          policy: redis
          redis:
            host: redis-11926.crce179.ap-south-1-1.ec2.redns.redis-cloud.com
            port: 11926
            username: default
            password: ezVdcJrF68Cq5hebnsv3AwUBIlC0ffu2
            database: 0
            ssl: true
            ssl_verify: false
            server_name: redis-11926.crce179.ap-south-1-1.ec2.redns.redis-cloud.com

  - username: power-user
    keyauth_credentials:
      - key: power-key-67890
    plugins:
      # Redis-backed rate limiting per consumer
      - name: rate-limiting
        config:
          minute: 50
          policy: redis
          redis:
            host: redis-11926.crce179.ap-south-1-1.ec2.redns.redis-cloud.com
            port: 11926
            username: default
            password: ezVdcJrF68Cq5hebnsv3AwUBIlC0ffu2
            database: 0
            ssl: true
            ssl_verify: false
            server_name: redis-11926.crce179.ap-south-1-1.ec2.redns.redis-cloud.com
